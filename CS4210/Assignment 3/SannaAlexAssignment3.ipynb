{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**CS4210 Fall 2023 Project Assignment 3 | By: Alexander J Sanna**\n",
        "\n"
      ],
      "metadata": {
        "id": "WWM_ckUHBU2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description:** This is my submission for the CS4210 Assignment three competition. This is a working convolution neural network designed to predict emotions based on 48x48 pixel image input. The competition is designed to have a dataset input of 2304 points representing the image and cooresponding labels (0,1,2) to represent emotions respectively. PYTORCH is the only library used.\n",
        "\n",
        "The code is littered with comments explaining choices and techniques used.\n",
        "With any questions please contact ajsanna@cpp.edu"
      ],
      "metadata": {
        "id": "K4zUGjJlegZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing my data sets in google drive for ease of use.\n",
        "# To run this code adequately, create a folder: 'datasets' inside of the google colab folder and store data files inside.\n",
        "# If not running on colab, please import datasets and labels accordingly. This program is desined for file x containing data and file y containing labels.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!ls -l ./gdrive/MyDrive/Colab\\ Notebooks/datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m13ljf5gB_u9",
        "outputId": "5d68f8f8-f92d-497d-c8b0-324212da9818"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "total 164269\n",
            "-rw------- 1 root root     23875 Oct 17 04:57 diabetes2.csv\n",
            "-rw------- 1 root root     30623 Nov 30 17:11 submission.csv\n",
            "-rw------- 1 root root  33075636 Nov 18 08:26 test_data.csv\n",
            "-rw------- 1 root root 135047556 Nov 18 08:26 train_data.csv\n",
            "-rw------- 1 root root     32350 Nov 20 18:41 train_target.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Loading Data into file via PANDAS**"
      ],
      "metadata": {
        "id": "TInG28tlECVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# load data from file located on google drive using pandas readcsv method.\n",
        "train_data = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/datasets/train_data.csv', header = None).to_numpy()\n",
        "train_target = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/datasets/train_target.csv', header = None).to_numpy().flatten()\n",
        "\n",
        "val_data = train_data[0:3235]\n",
        "val_target = train_target[0:3235]\n",
        "train_data = train_data[3235:]\n",
        "train_target = train_target[3235:]\n",
        "\n",
        "#The lines above split the data into validation and training sets to get a sense of how accurate our model is later on when we begin training."
      ],
      "metadata": {
        "id": "YTZFWX8xD-H3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Verifying Data size coorolations.\n",
        "print(\"Train Data: \",train_data.shape)\n",
        "print(\"Train Target: \",train_target.shape)\n",
        "print(\"Validation Data: \",val_data.shape)\n",
        "print(\"Validation Target: \",val_target.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7YolENbEu6t",
        "outputId": "8376911d-0b13-4193-ae48-bd074fa10634"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data:  (12940, 2304)\n",
            "Train Target:  (12940,)\n",
            "Validation Data:  (3235, 2304)\n",
            "Validation Target:  (3235,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Data Preprocessing:** Creating the data loader objects."
      ],
      "metadata": {
        "id": "PnsZs6brFLKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch.utils.data as data_utils\n",
        "from torch.nn.functional import normalize\n",
        "\n",
        "#Device selects GPU for accelerated runtimes.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#this line below converts the numpy array into a tensor datatype. VERY IMPORTANT TRAIN DATA STEP.\n",
        "train_tensor = torch.from_numpy(train_data).type(torch.float32).view(-1,2304)\n",
        "target_tensor =  torch.from_numpy(train_target).type(dtype = torch.long)\n",
        "\n",
        "val_tensor = torch.from_numpy(val_data).type(torch.float32).view(-1,2304)\n",
        "valid_target =  torch.from_numpy(val_target).type(dtype = torch.long)\n",
        "\n",
        "#Below is an optional normalization tactic that can be used. I tested and didnt see a large difference.\n",
        "#mean, std, var = torch.mean(train_tensor), torch.std(train_tensor), torch.var(train_tensor)\n",
        "#train_tensor = (train_tensor-mean)/std\n",
        "#train_tensor = normalize(train_tensor, p=1.0, dim = 0)\n",
        "\n",
        "#This line shapes our data in the 48x48 format for image recognition purposes.\n",
        "train_tensor = train_tensor.reshape(-1, 1, 48, 48)\n",
        "val_tensor = val_tensor.reshape(-1, 1, 48, 48)\n",
        "\n",
        "''' The Following code crates the pytorch dataloader objects for training purposes later.'''\n",
        "trainloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_tensor, target_tensor), shuffle=True, batch_size=512)\n",
        "validloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(val_tensor, valid_target), shuffle=False, batch_size=512)\n",
        "\n",
        "\n",
        "#Testing the data loader output for both train and validation:\n",
        "i1, l1 = next(iter(trainloader))\n",
        "print(\"Train Labels:\", l1.shape)\n",
        "print(\"Train Images:\", i1.shape)\n",
        "\n",
        "v1, v2 = next(iter(validloader))\n",
        "print(\"Valid Labels:\", v2.shape)\n",
        "print(\"Valid Images:\", v1.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SozYf6YtFQIL",
        "outputId": "bd150981-0a2e-415d-9021-dcadc3529291"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Labels: torch.Size([512])\n",
            "Train Images: torch.Size([512, 1, 48, 48])\n",
            "Valid Labels: torch.Size([512])\n",
            "Valid Images: torch.Size([512, 1, 48, 48])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code is Organized.**\n",
        "Lets start building our model."
      ],
      "metadata": {
        "id": "cBQppEHgKsCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Final number of outputs from our CNN.\n",
        "n_out = 3\n",
        "\n",
        "\n",
        "# I have experimented with a bunch of different models as this cell will show.\n",
        "# The one not commented out was the model I was able to reach a maximum accuracy score with.\n",
        "'''\n",
        "model = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(8, 4, kernel_size=3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(144, 72),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(72, 36),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(36, n_out)\n",
        ")\n",
        "'''\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 96, kernel_size=3, padding=1)\n",
        "        self.act1 = nn.Tanh()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(96, 48, kernel_size=3, padding=1)\n",
        "        self.act2 = nn.Tanh()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.conv3 = nn.Conv2d(48, 32, kernel_size=3, padding=1)\n",
        "        self.act3 = nn.Tanh()\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.conv4 = nn.Conv2d(32, 16, kernel_size=3, padding=1)\n",
        "        self.act4 = nn.Tanh()\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "        self.conv5 = nn.Conv2d(16, 4, kernel_size=3, padding=1)\n",
        "        self.act5 = nn.Tanh()\n",
        "        self.pool5 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(4, 72)\n",
        "        self.act3 = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(72, n_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.pool1(self.act1(self.conv1(x)))\n",
        "        out = self.pool2(self.act2(self.conv2(out)))\n",
        "        out = self.pool3(self.act3(self.conv3(out)))\n",
        "        out = self.pool4(self.act4(self.conv4(out)))\n",
        "        out = self.pool5(self.act5(self.conv5(out)))\n",
        "\n",
        "        #print(out.shape)\n",
        "        out = out.view(-1, 4) # <1>\n",
        "        out = self.act3(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "model = Net()\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, n_chans):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
        "                              padding=1, bias=False)  # <1>\n",
        "\n",
        "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
        "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
        "                                      nonlinearity='relu')  # <2>\n",
        "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
        "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.batch_norm(out)\n",
        "        out = torch.relu(out)\n",
        "        #print(out.shape)\n",
        "        return out + x\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NetResDeep(nn.Module):\n",
        "    def __init__(self, n_chans1=32, n_blocks=10):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(1, n_chans1, kernel_size=3, padding=1)\n",
        "        self.resblocks = nn.Sequential(\n",
        "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
        "\n",
        "        self.fc1 = nn.Linear(12 * 12 * n_chans1, 32)\n",
        "        self.fc2 = nn.Linear(32, n_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = self.resblocks(out)\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        #print(out.shape)\n",
        "        out = out.view(-1, 12 * 12 * self.n_chans1)\n",
        "        out = torch.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        #print(out.shape)\n",
        "        return out\n",
        "\n",
        "model = NetResDeep(n_chans1=48, n_blocks=10)\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "#Move model to GPU for accelerated runtime.\n",
        "model.to(device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFDf25HuLMO5",
        "outputId": "2f223905-cc4b-46c5-c9f2-1fd3d9aa77f0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (act1): Tanh()\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (act2): Tanh()\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (act3): Tanh()\n",
              "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv4): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (act4): Tanh()\n",
              "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv5): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (act5): Tanh()\n",
              "  (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=4, out_features=72, bias=True)\n",
              "  (fc2): Linear(in_features=72, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Loop**\n",
        "This is where we will run our train data through the model we have built in predetermined batch sizes. Run our results through a loss function and optimize with standard gradient descent."
      ],
      "metadata": {
        "id": "ZymLqmNXhtl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "learning_rate = .05\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 100\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train(True)\n",
        "    for imgs, labels in trainloader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)   # move tensors to GPU for computation acceleration\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        #print(outputs.shape) #Debugging lol\n",
        "        train_loss = loss_fn(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in validloader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)   # move tensors to GPU for computation acceleration\n",
        "\n",
        "            outputs = model(imgs)\n",
        "            val_loss = loss_fn(outputs, labels)\n",
        "\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            total += labels.shape[0]\n",
        "            correct += int((predicted == labels).sum())\n",
        "\n",
        "    print(\"Epoch: %d, train_loss: %f, val_loss: %f, val_accuracy: %f\" % (epoch, float(train_loss), float(val_loss), (correct / total)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1nIEz1xNryF",
        "outputId": "78bdcb88-fd68-491b-fbc4-ed1415515487"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, train_loss: 1.044097, val_loss: 1.047668, val_accuracy: 0.436167\n",
            "Epoch: 1, train_loss: 1.056074, val_loss: 1.047877, val_accuracy: 0.436167\n",
            "Epoch: 2, train_loss: 1.066047, val_loss: 1.047880, val_accuracy: 0.436167\n",
            "Epoch: 3, train_loss: 1.078505, val_loss: 1.048643, val_accuracy: 0.436167\n",
            "Epoch: 4, train_loss: 1.042514, val_loss: 1.046804, val_accuracy: 0.436167\n",
            "Epoch: 5, train_loss: 1.077752, val_loss: 1.048081, val_accuracy: 0.436167\n",
            "Epoch: 6, train_loss: 1.050908, val_loss: 1.046052, val_accuracy: 0.436167\n",
            "Epoch: 7, train_loss: 1.078371, val_loss: 1.046007, val_accuracy: 0.436167\n",
            "Epoch: 8, train_loss: 1.087743, val_loss: 1.048241, val_accuracy: 0.436167\n",
            "Epoch: 9, train_loss: 1.046343, val_loss: 1.041819, val_accuracy: 0.436167\n",
            "Epoch: 10, train_loss: 1.071865, val_loss: 1.041049, val_accuracy: 0.436167\n",
            "Epoch: 11, train_loss: 1.079712, val_loss: 1.035480, val_accuracy: 0.436167\n",
            "Epoch: 12, train_loss: 1.030807, val_loss: 1.020874, val_accuracy: 0.438022\n",
            "Epoch: 13, train_loss: 1.100847, val_loss: 1.059900, val_accuracy: 0.435240\n",
            "Epoch: 14, train_loss: 1.013785, val_loss: 1.010167, val_accuracy: 0.438331\n",
            "Epoch: 15, train_loss: 0.956212, val_loss: 0.995595, val_accuracy: 0.456260\n",
            "Epoch: 16, train_loss: 0.927405, val_loss: 0.946406, val_accuracy: 0.525811\n",
            "Epoch: 17, train_loss: 0.940702, val_loss: 0.949273, val_accuracy: 0.548068\n",
            "Epoch: 18, train_loss: 0.902521, val_loss: 0.924923, val_accuracy: 0.568161\n",
            "Epoch: 19, train_loss: 0.941519, val_loss: 0.917586, val_accuracy: 0.524266\n",
            "Epoch: 20, train_loss: 0.894192, val_loss: 0.887202, val_accuracy: 0.573725\n",
            "Epoch: 21, train_loss: 1.014253, val_loss: 0.941460, val_accuracy: 0.483771\n",
            "Epoch: 22, train_loss: 0.937338, val_loss: 0.927752, val_accuracy: 0.558578\n",
            "Epoch: 23, train_loss: 0.915867, val_loss: 0.881305, val_accuracy: 0.568161\n",
            "Epoch: 24, train_loss: 0.835733, val_loss: 0.841167, val_accuracy: 0.605255\n",
            "Epoch: 25, train_loss: 0.854637, val_loss: 0.837438, val_accuracy: 0.579907\n",
            "Epoch: 26, train_loss: 0.803462, val_loss: 0.850418, val_accuracy: 0.592890\n",
            "Epoch: 27, train_loss: 0.784105, val_loss: 0.867442, val_accuracy: 0.584544\n",
            "Epoch: 28, train_loss: 0.856326, val_loss: 0.811681, val_accuracy: 0.616074\n",
            "Epoch: 29, train_loss: 0.949794, val_loss: 0.962238, val_accuracy: 0.528284\n",
            "Epoch: 30, train_loss: 0.743408, val_loss: 0.831474, val_accuracy: 0.609274\n",
            "Epoch: 31, train_loss: 0.736110, val_loss: 0.812051, val_accuracy: 0.628130\n",
            "Epoch: 32, train_loss: 0.787312, val_loss: 0.767409, val_accuracy: 0.638640\n",
            "Epoch: 33, train_loss: 0.759799, val_loss: 0.785730, val_accuracy: 0.630912\n",
            "Epoch: 34, train_loss: 0.936905, val_loss: 1.450142, val_accuracy: 0.366924\n",
            "Epoch: 35, train_loss: 1.074517, val_loss: 1.048820, val_accuracy: 0.436167\n",
            "Epoch: 36, train_loss: 1.067399, val_loss: 1.087932, val_accuracy: 0.389181\n",
            "Epoch: 37, train_loss: 1.079363, val_loss: 1.059420, val_accuracy: 0.444822\n",
            "Epoch: 38, train_loss: 1.022138, val_loss: 1.035142, val_accuracy: 0.443586\n",
            "Epoch: 39, train_loss: 1.053336, val_loss: 1.031193, val_accuracy: 0.436785\n",
            "Epoch: 40, train_loss: 0.796226, val_loss: 0.806662, val_accuracy: 0.617311\n",
            "Epoch: 41, train_loss: 0.740283, val_loss: 0.816956, val_accuracy: 0.630294\n",
            "Epoch: 42, train_loss: 0.680022, val_loss: 0.808718, val_accuracy: 0.636785\n",
            "Epoch: 43, train_loss: 0.740411, val_loss: 0.845428, val_accuracy: 0.624420\n",
            "Epoch: 44, train_loss: 0.712385, val_loss: 0.758333, val_accuracy: 0.655641\n",
            "Epoch: 45, train_loss: 0.768190, val_loss: 0.851007, val_accuracy: 0.610510\n",
            "Epoch: 46, train_loss: 0.721459, val_loss: 0.792749, val_accuracy: 0.650696\n",
            "Epoch: 47, train_loss: 0.721339, val_loss: 0.761559, val_accuracy: 0.667388\n",
            "Epoch: 48, train_loss: 0.700804, val_loss: 0.842141, val_accuracy: 0.656569\n",
            "Epoch: 49, train_loss: 0.657619, val_loss: 0.820949, val_accuracy: 0.653787\n",
            "Epoch: 50, train_loss: 0.991809, val_loss: 1.007650, val_accuracy: 0.443895\n",
            "Epoch: 51, train_loss: 0.759386, val_loss: 0.911125, val_accuracy: 0.632457\n",
            "Epoch: 52, train_loss: 0.721006, val_loss: 0.793593, val_accuracy: 0.643277\n",
            "Epoch: 53, train_loss: 0.653798, val_loss: 0.862496, val_accuracy: 0.652550\n",
            "Epoch: 54, train_loss: 0.769560, val_loss: 0.813220, val_accuracy: 0.657187\n",
            "Epoch: 55, train_loss: 0.660863, val_loss: 0.800569, val_accuracy: 0.665224\n",
            "Epoch: 56, train_loss: 0.735171, val_loss: 0.832208, val_accuracy: 0.649150\n",
            "Epoch: 57, train_loss: 0.622925, val_loss: 0.744212, val_accuracy: 0.685008\n",
            "Epoch: 58, train_loss: 0.726125, val_loss: 0.880056, val_accuracy: 0.641731\n",
            "Epoch: 59, train_loss: 0.569842, val_loss: 0.759660, val_accuracy: 0.662751\n",
            "Epoch: 60, train_loss: 0.668871, val_loss: 0.815222, val_accuracy: 0.668315\n",
            "Epoch: 61, train_loss: 0.720773, val_loss: 0.746712, val_accuracy: 0.683153\n",
            "Epoch: 62, train_loss: 0.496646, val_loss: 0.752696, val_accuracy: 0.693663\n",
            "Epoch: 63, train_loss: 0.594296, val_loss: 0.836279, val_accuracy: 0.671716\n",
            "Epoch: 64, train_loss: 0.620273, val_loss: 0.830730, val_accuracy: 0.702628\n",
            "Epoch: 65, train_loss: 0.739412, val_loss: 0.821999, val_accuracy: 0.655951\n",
            "Epoch: 66, train_loss: 0.552922, val_loss: 0.730729, val_accuracy: 0.702318\n",
            "Epoch: 67, train_loss: 0.578661, val_loss: 0.834374, val_accuracy: 0.648841\n",
            "Epoch: 68, train_loss: 0.560541, val_loss: 0.765190, val_accuracy: 0.674498\n",
            "Epoch: 69, train_loss: 0.607457, val_loss: 0.790975, val_accuracy: 0.692736\n",
            "Epoch: 70, train_loss: 0.568197, val_loss: 0.869105, val_accuracy: 0.681607\n",
            "Epoch: 71, train_loss: 0.635185, val_loss: 0.834817, val_accuracy: 0.646986\n",
            "Epoch: 72, train_loss: 0.623761, val_loss: 0.913092, val_accuracy: 0.665533\n",
            "Epoch: 73, train_loss: 0.711532, val_loss: 0.864334, val_accuracy: 0.669243\n",
            "Epoch: 74, train_loss: 0.575441, val_loss: 0.756132, val_accuracy: 0.701700\n",
            "Epoch: 75, train_loss: 0.534661, val_loss: 0.779030, val_accuracy: 0.692427\n",
            "Epoch: 76, train_loss: 0.634000, val_loss: 0.741239, val_accuracy: 0.683153\n",
            "Epoch: 77, train_loss: 0.618425, val_loss: 0.996366, val_accuracy: 0.623802\n",
            "Epoch: 78, train_loss: 0.722556, val_loss: 0.753729, val_accuracy: 0.720247\n",
            "Epoch: 79, train_loss: 0.540050, val_loss: 0.775176, val_accuracy: 0.702318\n",
            "Epoch: 80, train_loss: 0.591911, val_loss: 0.828172, val_accuracy: 0.690572\n",
            "Epoch: 81, train_loss: 0.619983, val_loss: 0.814609, val_accuracy: 0.677589\n",
            "Epoch: 82, train_loss: 0.639384, val_loss: 0.798196, val_accuracy: 0.637713\n",
            "Epoch: 83, train_loss: 1.066566, val_loss: 1.054236, val_accuracy: 0.436167\n",
            "Epoch: 84, train_loss: 1.043122, val_loss: 1.050608, val_accuracy: 0.436167\n",
            "Epoch: 85, train_loss: 1.045456, val_loss: 1.046077, val_accuracy: 0.436167\n",
            "Epoch: 86, train_loss: 1.012145, val_loss: 1.051156, val_accuracy: 0.436167\n",
            "Epoch: 87, train_loss: 0.970693, val_loss: 0.991334, val_accuracy: 0.447913\n",
            "Epoch: 88, train_loss: 0.966278, val_loss: 1.097622, val_accuracy: 0.484389\n",
            "Epoch: 89, train_loss: 0.790974, val_loss: 0.830653, val_accuracy: 0.641731\n",
            "Epoch: 90, train_loss: 0.604288, val_loss: 0.930466, val_accuracy: 0.627202\n",
            "Epoch: 91, train_loss: 0.570901, val_loss: 0.760184, val_accuracy: 0.699227\n",
            "Epoch: 92, train_loss: 0.666771, val_loss: 0.819294, val_accuracy: 0.681298\n",
            "Epoch: 93, train_loss: 0.627992, val_loss: 0.800348, val_accuracy: 0.691499\n",
            "Epoch: 94, train_loss: 0.550463, val_loss: 0.815178, val_accuracy: 0.687481\n",
            "Epoch: 95, train_loss: 0.746386, val_loss: 0.999544, val_accuracy: 0.638640\n",
            "Epoch: 96, train_loss: 0.566693, val_loss: 0.823469, val_accuracy: 0.697682\n",
            "Epoch: 97, train_loss: 0.541291, val_loss: 0.778688, val_accuracy: 0.707264\n",
            "Epoch: 98, train_loss: 0.371864, val_loss: 0.853148, val_accuracy: 0.698609\n",
            "Epoch: 99, train_loss: 0.521253, val_loss: 0.876544, val_accuracy: 0.679753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The following code is designed to import the test file and run it through our model to log predictions.\n",
        "# The predictions are then stored in an dictionary and exported to a CSV file for submission.\n",
        "\n",
        "test_data = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/datasets/test_data.csv', header = None).to_numpy()\n",
        "test_tensor = torch.from_numpy(test_data).type(torch.float32).view(-1,2304)\n",
        "test_tensor = test_tensor.reshape(-1, 1, 48, 48)\n",
        "test_tensor = test_tensor.to(device)\n",
        "print(test_tensor.shape)\n",
        "\n",
        "\n",
        "predictions = model(test_tensor)\n",
        "_, predicted = torch.max(predictions, dim=1)\n",
        "print(len(predicted))\n",
        "\n"
      ],
      "metadata": {
        "id": "d3dl7pi-N-MN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "216f679f-3e68-4bbd-9091-0ad0f8edb9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3965, 1, 48, 48])\n",
            "3965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fields = ['Id', \"Category\"]\n",
        "import csv\n",
        "\n",
        "data = []\n",
        "val = len(predicted)\n",
        "#print(val)\n",
        "for x in range(val):\n",
        "  data.append( [x, predicted[x].item()])\n",
        "  #print(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open('/content/gdrive/MyDrive/Colab Notebooks/datasets/submission.csv', 'w') as csvfile:\n",
        "  csvwriter = csv.writer(csvfile)\n",
        "  csvwriter.writerow(fields)\n",
        "  csvwriter.writerows(data)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y6kQhNeJInmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/datasets/submission.csv')\n",
        "test.head\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm7yk7GsKhtg",
        "outputId": "634e6f5d-03bb-419d-83fc-1ee62292eccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of         Id  Category\n",
              "0        0         1\n",
              "1        1         0\n",
              "2        2         1\n",
              "3        3         1\n",
              "4        4         1\n",
              "...    ...       ...\n",
              "3960  3960         0\n",
              "3961  3961         0\n",
              "3962  3962         1\n",
              "3963  3963         2\n",
              "3964  3964         2\n",
              "\n",
              "[3965 rows x 2 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = '/content/gdrive/MyDrive/Colab Notebooks/datasets/submission.csv'\n",
        "# opening the file with w+ mode truncates the file\n",
        "f = open(filename, \"w+\")\n",
        "f.close()"
      ],
      "metadata": {
        "id": "qJ6apRDTQHzE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}